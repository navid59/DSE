# HBase Distributed System Testing

This project is designed to test and evaluate the performance of an HBase distributed setup using Docker and multi-threaded Python load testing scripts. It simulates real-world scenarios and captures key performance metrics such as latency, throughput, and fault tolerance.

## ðŸ“¦ Components

- **Docker Compose** setup for:
  - Apache ZooKeeper
  - HBase Master
  - HBase RegionServers (configurable)
- **Python Load Test Script** using `happybase` and `threading`
- **CSV Result Output** for post-analysis
- **Real-time logging** to console during execution

---


## ðŸ“Š Output

- Real-time operation logs printed in terminal
- Results saved to `*.csv` in the **Report** folder.

---

## ðŸ§ª Tested Scenarios

### âœ… Scenario 1: Baseline Load Test

- **Goal**: Measure normal performance under steady load.
- **Setup**: 1 HBase Master, 2 RegionServers, 5â€“10 threads.
- **Metrics**: Latency, throughput, error rate.
- **Why**: Establish baseline system behavior.

### ðŸ”§ Scenario 2: Failure Simulation

- **Goal**: Test fault tolerance by stopping one RegionServer mid-test.
- **Setup**: Same as baseline.
- **How**: After 30 seconds of load
- **Metrics**: Error spike, latency, recovery time.
- **Why**: Validate system resilience.

### ðŸ“ˆ Scenario 3: Scaling Test

- **Goal**: See if adding RegionServers improves throughput.
- **Steps**:
  1. Run with 1 RS
  2. Then with 2 RS
  3. Then with 3 RS
- **Metrics**: Latency and throughput as RS count changes.
- **Why**: Measure horizontal scalability.

### ðŸ”¥ Scenario 4: Stress Test

- **Goal**: Push HBase to its limits.
- **Setup**: 2â€“3 RS, 20â€“50 threads.
- **Duration**: 5â€“10 minutes.
- **Metrics**: Max sustainable throughput, error rates, bottlenecks.

---

## ðŸ“Œ Requirements

- Docker
- Python 3.7+
- Python dependencies: `happybase`

---

## ðŸ§  Notes

- This test made by geting help of **Open AI**
- By getting help of **Open AI** , I tried to undrestand the progress
